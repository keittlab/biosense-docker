#!/usr/bin/env python3

import os
import sys
import time
import signal
import shutil
import re
from datetime import datetime, timedelta
import logging
from logging.handlers import RotatingFileHandler

from sqlalchemy import (
    create_engine,
    Column,
    Integer,
    String,
    Float,
    DateTime,
    Index,
    Boolean,
    inspect,
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

import toml
from birdnetlib import Recording
from birdnetlib.analyzer import Analyzer


# Configure logging
log_dir = "/var/log/biosense/"
log_file = os.path.join(log_dir, "run-birdnet.log")
log_handler = RotatingFileHandler(
    log_file, maxBytes=1 * 1024 * 1024, backupCount=5
)  # 1 MB per file, 5 backup files
logging.basicConfig(
    level=logging.INFO,
    handlers=[log_handler],
    format="%(asctime)s - %(levelname)s - %(message)s",
)


def read_config(config_file):
    """Read and parse configuration file."""
    try:
        if not os.path.exists(config_file):
            raise FileNotFoundError(f"Configuration file does not exist: {config_file}")

        logging.info(f"Reading configuration file: {config_file}")
        with open(config_file, "r") as f:
            content = toml.load(f)

        if not content:
            raise ValueError("Configuration file is empty.")

        return content["DEFAULT"]
    except Exception as e:
        logging.error(f"Error reading configuration file: {e}")
        sys.exit(1)


def load_location(location_file):
    """Load latitude and longitude from the location file."""
    try:
        if not os.path.exists(location_file):
            raise FileNotFoundError(f"Location file does not exist: {location_file}")

        with open(location_file, "r") as f:
            location = toml.load(f)

        latitude = location.get("latitude")
        longitude = location.get("longitude")
        if latitude is None or longitude is None:
            raise ValueError("Latitude or longitude is missing in the location file.")

        return float(latitude), float(longitude)
    except Exception as e:
        logging.error(f"Error reading location file: {e}")
        sys.exit(1)


config_file = "/etc/biosense/run-birdnet.conf"
location_file = "/etc/biosense/location.conf"

config = read_config(config_file)
LATITUDE, LONGITUDE = load_location(location_file)

RECORDING_DIR = config.get(
    "RECORDING_DIR", "/home/biosense/datastore/sound_recordings/"
)
EXPORT_DIR = config.get(
    "EXPORT_DIR", "/home/biosense/datastore/sound_analysis_results/"
)
PROCESSED_DIR = config.get(
    "PROCESSED_DIR", "/home/biosense/datastore/processed_recordings/"
)
SEGMENT_LENGTH = int(config.get("SEGMENT_LENGTH", 3))
DB_PATH = config.get("DB_PATH", "/home/biosense/datastore/birdnet_results.db")
MIN_CONF = float(config.get("MIN_CONF", 0.1))
OVERLAP = float(config.get("OVERLAP", 1.5))
SENSITIVITY = float(config.get("SENSITIVITY", 1.0))

HOSTNAME = os.uname().nodename.replace("-", "_")

Base = declarative_base()


class Detection(Base):
    __tablename__ = "birdnet_detections"
    id = Column(Integer, primary_key=True, autoincrement=True)
    hostname = Column(String)
    latitude = Column(Float)
    longitude = Column(Float)
    timestamp = Column(DateTime)
    start_time = Column(Float)
    end_time = Column(Float)
    sci_name = Column(String, nullable=False)
    com_name = Column(String, nullable=False)
    confidence = Column(Float)
    is_likely = Column(Boolean, nullable=True)
    source_recording = Column(String, nullable=True)
    file_path = Column(String, nullable=True)

    __table_args__ = (
        Index("idx_com_name_timestamp", "com_name", "timestamp"),
        Index("idx_start_end_time", "start_time", "end_time"),
        Index("idx_com_name_confidence", "com_name", "confidence"),
        Index("idx_sci_name", "sci_name"),
    )


engine = create_engine(f"sqlite:///{DB_PATH}")
Base.metadata.create_all(engine)

session = sessionmaker(bind=engine)()


def validate_database(engine, expected_columns):
    try:
        inspector = inspect(engine)
        if "birdnet_detections" in inspector.get_table_names():
            columns = inspector.get_columns("birdnet_detections")
            column_names = [column["name"] for column in columns]
            if column_names == expected_columns:
                logging.info("Database schema is valid.")
                return True
            else:
                logging.warning(
                    f"Database schema mismatch. Expected columns: {expected_columns}, Found columns: {column_names}"
                )
        else:
            logging.warning("Table 'birdnet_detections' does not exist.")
        return False
    except Exception as e:
        logging.error(f"Error inspecting database schema: {e}")
        return False


def analyze_recordings():
    try:
        analyzer = Analyzer()
    except Exception as e:
        logging.error(f"Failed to initialize Analyzer: {e}")
        return

    while True:
        logging.info("Starting to analyze recordings.")
        current_time = time.time()
        files = sorted(
            os.listdir(RECORDING_DIR),
            key=lambda x: os.path.getctime(os.path.join(RECORDING_DIR, x)),
        )
        flac_files = [f for f in files if f.endswith(".flac")]

        for filename in flac_files:
            filepath = os.path.join(RECORDING_DIR, filename)
            if current_time - os.path.getmtime(filepath) < 300:
                logging.info(f"Skipping recent file: {filepath}")
                continue

            logging.info(f"Processing file: {filepath}")
            recording_timestamp = get_creation_time(filepath)
            recording = Recording(
                analyzer,
                filepath,
                lat=LATITUDE,
                lon=LONGITUDE,
                overlap=OVERLAP,
                min_conf=MIN_CONF,
                sensitivity=SENSITIVITY,
                date=recording_timestamp,
                return_all_detections=True,
            )
            try:
                recording.analyze()
                new_source_recording_path = on_analyze_complete(
                    recording, recording_timestamp
                )
                extract_detected_segments(
                    recording, recording_timestamp, new_source_recording_path
                )
            except Exception as e:
                on_error(recording, e)

        time.sleep(300)


def main():
    signal.signal(signal.SIGINT, lambda sig, frame: sys.exit(0))
    logging.info("Starting main loop.")
    analyze_recordings()


if __name__ == "__main__":
    main()
